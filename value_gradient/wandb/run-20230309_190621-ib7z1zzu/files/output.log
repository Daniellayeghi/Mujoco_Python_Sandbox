Creating window glfw
Epochs: 1, Loss: 12218475520.0, lr: 0.004, time: 50
Epochs: 2, Loss: 12060390400.0, lr: 0.004, time: 50
Epochs: 3, Loss: 11909320704.0, lr: 0.004, time: 50
Epochs: 4, Loss: 11761805312.0, lr: 0.004, time: 50
Epochs: 5, Loss: 11618282496.0, lr: 0.004, time: 50
Epochs: 6, Loss: 11477304320.0, lr: 0.004, time: 50
Epochs: 7, Loss: 10768857088.0, lr: 0.004, time: 59
Epochs: 8, Loss: 10633054208.0, lr: 0.004, time: 59
Epochs: 9, Loss: 10496249856.0, lr: 0.004, time: 59
Epochs: 10, Loss: 10359754752.0, lr: 0.004, time: 59
Epochs: 11, Loss: 10217788416.0, lr: 0.004, time: 59
Epochs: 12, Loss: 10075130880.0, lr: 0.004, time: 59
Epochs: 13, Loss: 9929150464.0, lr: 0.004, time: 59
Epochs: 14, Loss: 9813773312.0, lr: 0.004, time: 65
Epochs: 15, Loss: 9654396928.0, lr: 0.004, time: 65
Epochs: 16, Loss: 9475816448.0, lr: 0.004, time: 65
Epochs: 17, Loss: 9316129792.0, lr: 0.004, time: 65
Epochs: 18, Loss: 9115000832.0, lr: 0.004, time: 65
Epochs: 19, Loss: 8907819008.0, lr: 0.004, time: 65
Epochs: 20, Loss: 8717588480.0, lr: 0.004, time: 65
Epochs: 21, Loss: 8632616960.0, lr: 0.004, time: 70
Epochs: 22, Loss: 8375745024.0, lr: 0.004, time: 70
Epochs: 23, Loss: 8118266368.0, lr: 0.004, time: 70
Epochs: 24, Loss: 7836242432.0, lr: 0.004, time: 70
Epochs: 25, Loss: 7546859008.0, lr: 0.004, time: 70
Epochs: 26, Loss: 7263434240.0, lr: 0.004, time: 70
Epochs: 27, Loss: 6980787712.0, lr: 0.004, time: 70
Epochs: 28, Loss: 6766214656.0, lr: 0.004, time: 74
Epochs: 29, Loss: 6494718976.0, lr: 0.004, time: 74
Epochs: 30, Loss: 6234481664.0, lr: 0.004, time: 74
Epochs: 31, Loss: 5987069952.0, lr: 0.004, time: 74
Epochs: 32, Loss: 5771435520.0, lr: 0.004, time: 74
Epochs: 33, Loss: 5541459968.0, lr: 0.004, time: 74
Epochs: 34, Loss: 5332204032.0, lr: 0.004, time: 74
Epochs: 35, Loss: 5239419904.0, lr: 0.004, time: 78
Epochs: 36, Loss: 5033188864.0, lr: 0.004, time: 78
Epochs: 37, Loss: 4918572544.0, lr: 0.004, time: 78
Epochs: 38, Loss: 4635979264.0, lr: 0.004, time: 78
Epochs: 39, Loss: 4375659520.0, lr: 0.004, time: 78
Epochs: 40, Loss: 4150878720.0, lr: 0.004, time: 78
Epochs: 41, Loss: 4012289280.0, lr: 0.004, time: 78
Epochs: 42, Loss: 4021666048.0, lr: 0.004, time: 81
Epochs: 43, Loss: 3945276672.0, lr: 0.004, time: 81
Epochs: 44, Loss: 3793820928.0, lr: 0.004, time: 81
Epochs: 45, Loss: 3695802368.0, lr: 0.004, time: 81
Epochs: 46, Loss: 3576549376.0, lr: 0.004, time: 81
Epochs: 47, Loss: 3516507648.0, lr: 0.004, time: 81
Epochs: 48, Loss: 3526246656.0, lr: 0.004, time: 81
Epochs: 49, Loss: 3586442496.0, lr: 0.004, time: 84
Epochs: 50, Loss: 3520531456.0, lr: 0.004, time: 84
Epochs: 51, Loss: 3635809024.0, lr: 0.004, time: 84
Epochs: 52, Loss: 3454065664.0, lr: 0.004, time: 84
Epochs: 53, Loss: 3474881280.0, lr: 0.004, time: 84
Epochs: 54, Loss: 3459802880.0, lr: 0.004, time: 84
Epochs: 55, Loss: 3436817152.0, lr: 0.004, time: 84
Epochs: 56, Loss: 3782875136.0, lr: 0.004, time: 87
Epochs: 57, Loss: 3802205184.0, lr: 0.004, time: 87
Epochs: 58, Loss: 3794359552.0, lr: 0.004, time: 87
Epochs: 59, Loss: 3816492032.0, lr: 0.004, time: 87
Epochs: 60, Loss: 3807865856.0, lr: 0.004, time: 87
Epochs: 61, Loss: 3797568768.0, lr: 0.004, time: 87
Epochs: 62, Loss: 3785606656.0, lr: 0.004, time: 87
Epochs: 63, Loss: 4079214592.0, lr: 0.004, time: 89
Epochs: 64, Loss: 4063232000.0, lr: 0.004, time: 89
Epochs: 65, Loss: 4044710400.0, lr: 0.004, time: 89
Epochs: 66, Loss: 4023641856.0, lr: 0.004, time: 89
Epochs: 67, Loss: 4004219136.0, lr: 0.004, time: 89
Epochs: 68, Loss: 4012438784.0, lr: 0.004, time: 89
Epochs: 69, Loss: 3983036160.0, lr: 0.004, time: 89
Epochs: 70, Loss: 4299307520.0, lr: 0.004, time: 91
Epochs: 71, Loss: 4256340224.0, lr: 0.004, time: 91
Epochs: 72, Loss: 4206165504.0, lr: 0.004, time: 91
Epochs: 73, Loss: 4147726336.0, lr: 0.004, time: 91
Epochs: 74, Loss: 4075884032.0, lr: 0.004, time: 91
Epochs: 75, Loss: 4007490304.0, lr: 0.004, time: 91
Epochs: 76, Loss: 4027411712.0, lr: 0.004, time: 91
Epochs: 77, Loss: 4430993408.0, lr: 0.004, time: 93
Epochs: 78, Loss: 4423838720.0, lr: 0.004, time: 93
Epochs: 79, Loss: 4481122816.0, lr: 0.004, time: 93
Epochs: 80, Loss: 4463822848.0, lr: 0.004, time: 93
Epochs: 81, Loss: 4519465472.0, lr: 0.004, time: 93
Epochs: 82, Loss: 4472522240.0, lr: 0.004, time: 93
Epochs: 83, Loss: 4497813504.0, lr: 0.004, time: 93
Epochs: 84, Loss: 4903003648.0, lr: 0.004, time: 95
Epochs: 85, Loss: 4921518080.0, lr: 0.004, time: 95
Epochs: 86, Loss: 4889001472.0, lr: 0.004, time: 95
Epochs: 87, Loss: 4848993792.0, lr: 0.004, time: 95
Epochs: 88, Loss: 4757914112.0, lr: 0.004, time: 95
Epochs: 89, Loss: 4700913152.0, lr: 0.004, time: 95
Epochs: 90, Loss: 4603977216.0, lr: 0.004, time: 95
Epochs: 91, Loss: 4936560640.0, lr: 0.004, time: 97
Epochs: 92, Loss: 4856672256.0, lr: 0.004, time: 97
Epochs: 93, Loss: 4772340736.0, lr: 0.004, time: 97
Epochs: 94, Loss: 4607526912.0, lr: 0.004, time: 97
Epochs: 95, Loss: 4514173952.0, lr: 0.004, time: 97
Epochs: 96, Loss: 4454305280.0, lr: 0.004, time: 97
Epochs: 97, Loss: 4393263616.0, lr: 0.004, time: 97
Epochs: 98, Loss: 4746617856.0, lr: 0.004, time: 99
Epochs: 99, Loss: 4673551360.0, lr: 0.004, time: 99
Epochs: 100, Loss: 4594913792.0, lr: 0.004, time: 99
Epochs: 101, Loss: 4507334656.0, lr: 0.004, time: 99
Epochs: 102, Loss: 4455684096.0, lr: 0.004, time: 99
Epochs: 103, Loss: 4467793920.0, lr: 0.004, time: 99
Epochs: 104, Loss: 4397710848.0, lr: 0.004, time: 99
Epochs: 105, Loss: 4757727232.0, lr: 0.004, time: 101
Epochs: 106, Loss: 4786211840.0, lr: 0.004, time: 101
Epochs: 107, Loss: 4742728192.0, lr: 0.004, time: 101
Epochs: 108, Loss: 4660903936.0, lr: 0.004, time: 101
Epochs: 109, Loss: 4610935296.0, lr: 0.004, time: 101
Epochs: 110, Loss: 4624417792.0, lr: 0.004, time: 101
Epochs: 111, Loss: 4568205824.0, lr: 0.004, time: 101
Epochs: 112, Loss: 4886931968.0, lr: 0.004, time: 103
Epochs: 113, Loss: 4813415424.0, lr: 0.004, time: 103
Epochs: 114, Loss: 4754203648.0, lr: 0.004, time: 103
Epochs: 115, Loss: 4730655232.0, lr: 0.004, time: 103
Epochs: 116, Loss: 4654997504.0, lr: 0.004, time: 103
########## Saving Trace ##########
Traceback (most recent call last):
  File "tv_value_synthesis_trajopt_cartpole.py", line 202, in <module>
    loss.backward()
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/_tensor.py", line 488, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "tv_value_synthesis_trajopt_cartpole.py", line 240, in <module>
    model_scripted = torch.jit.script(dyn_system.value_func.to('cpu'))  # Export to TorchScript
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/jit/_script.py", line 1287, in script
    obj, torch.jit._recursive.infer_methods_to_compile
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/jit/_recursive.py", line 476, in create_script_module
    return create_script_module_impl(nn_module, concrete_type, stubs_fn)
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/jit/_recursive.py", line 542, in create_script_module_impl
    create_methods_and_properties_from_stubs(concrete_type, method_stubs, property_stubs)
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/jit/_recursive.py", line 393, in create_methods_and_properties_from_stubs
    concrete_type._create_methods_and_properties(property_defs, property_rcbs, method_defs, method_rcbs, method_defaults)
RuntimeError:
attribute lookup is not defined on python value of type 'SimulationParams':
  File "tv_value_synthesis_trajopt_cartpole.py", line 74
    def forward(self, t, x):
        time = torch.ones((sim_params.nsim, 1, 1)).to(device) * t
                           ~~~~~~~~~~~~~~~ <--- HERE
        aug_x = torch.cat((x, time), dim=2)
        return self.nn(aug_x)