
Creating window glfw
Epochs: 0, Loss: 3270786304.0, lr: 0.004
Epochs: 1, Loss: 3195793664.0, lr: 0.004
Epochs: 2, Loss: 3106880512.0, lr: 0.004
Epochs: 3, Loss: 3030843648.0, lr: 0.004
Epochs: 4, Loss: 2971823104.0, lr: 0.004
Epochs: 5, Loss: 2912951296.0, lr: 0.004
Epochs: 6, Loss: 2854067968.0, lr: 0.004
Epochs: 7, Loss: 2801079040.0, lr: 0.004
Epochs: 8, Loss: 2754566912.0, lr: 0.004
Epochs: 9, Loss: 2710881536.0, lr: 0.004
Epochs: 10, Loss: 2667879936.0, lr: 0.004
Epochs: 11, Loss: 2626501120.0, lr: 0.004
Epochs: 12, Loss: 2588159232.0, lr: 0.004
Epochs: 13, Loss: 2552594432.0, lr: 0.004
Epochs: 14, Loss: 2518299136.0, lr: 0.004
Epochs: 15, Loss: 2484293120.0, lr: 0.004
Epochs: 16, Loss: 2450805248.0, lr: 0.004
Epochs: 17, Loss: 2418397440.0, lr: 0.004
Epochs: 18, Loss: 2386968576.0, lr: 0.004
Epochs: 19, Loss: 2355758080.0, lr: 0.004
Epochs: 20, Loss: 2324090112.0, lr: 0.004
Epochs: 21, Loss: 2291812608.0, lr: 0.004
Epochs: 22, Loss: 2258977792.0, lr: 0.004
Epochs: 23, Loss: 2225344512.0, lr: 0.004
Epochs: 24, Loss: 2190370048.0, lr: 0.004
Epochs: 25, Loss: 2153609472.0, lr: 0.004
Epochs: 26, Loss: 2114955776.0, lr: 0.004
Epochs: 27, Loss: 2074456704.0, lr: 0.004
Epochs: 28, Loss: 2032081024.0, lr: 0.004
Epochs: 29, Loss: 1987797120.0, lr: 0.004
Epochs: 30, Loss: 1941888000.0, lr: 0.004
Epochs: 31, Loss: 1895118592.0, lr: 0.004
Epochs: 32, Loss: 1848562944.0, lr: 0.004
Epochs: 33, Loss: 1803286400.0, lr: 0.004
Epochs: 34, Loss: 1760169472.0, lr: 0.004
Epochs: 35, Loss: 1719888256.0, lr: 0.004
Epochs: 36, Loss: 1682851584.0, lr: 0.004
Epochs: 37, Loss: 1649046656.0, lr: 0.004
Epochs: 38, Loss: 1618048896.0, lr: 0.004
Epochs: 39, Loss: 1589272448.0, lr: 0.004
Epochs: 40, Loss: 1562200064.0, lr: 0.004
Epochs: 41, Loss: 1536398592.0, lr: 0.004
Epochs: 42, Loss: 1511490944.0, lr: 0.004
Epochs: 43, Loss: 1487230592.0, lr: 0.004
Epochs: 44, Loss: 1463537280.0, lr: 0.004
Epochs: 45, Loss: 1440386304.0, lr: 0.004
Epochs: 46, Loss: 1417704064.0, lr: 0.004
Epochs: 47, Loss: 1395399296.0, lr: 0.004
Epochs: 48, Loss: 1373418880.0, lr: 0.004
Epochs: 49, Loss: 1351713280.0, lr: 0.004
Epochs: 50, Loss: 1330208128.0, lr: 0.004
Epochs: 51, Loss: 1308852992.0, lr: 0.004
Epochs: 52, Loss: 1287630592.0, lr: 0.004
Epochs: 53, Loss: 1266469376.0, lr: 0.004
Epochs: 54, Loss: 1245223296.0, lr: 0.004
Epochs: 55, Loss: 1223790464.0, lr: 0.004
Epochs: 56, Loss: 1202294400.0, lr: 0.004
Epochs: 57, Loss: 1180978560.0, lr: 0.004
Epochs: 58, Loss: 1159904256.0, lr: 0.004
Epochs: 59, Loss: 1138996736.0, lr: 0.004
Epochs: 60, Loss: 1118145920.0, lr: 0.004
Epochs: 61, Loss: 1097200896.0, lr: 0.004
Epochs: 62, Loss: 1075979008.0, lr: 0.004
Epochs: 63, Loss: 1054310144.0, lr: 0.004
Epochs: 64, Loss: 1032040320.0, lr: 0.004
Epochs: 65, Loss: 1008954240.0, lr: 0.004
Epochs: 66, Loss: 984665664.0, lr: 0.004
Epochs: 67, Loss: 958518464.0, lr: 0.004
Epochs: 68, Loss: 929521600.0, lr: 0.004
Epochs: 69, Loss: 896482432.0, lr: 0.004
Epochs: 70, Loss: 859425088.0, lr: 0.004
Epochs: 71, Loss: 821831872.0, lr: 0.004
Epochs: 72, Loss: 787467840.0, lr: 0.004
Epochs: 73, Loss: 760237056.0, lr: 0.004
Epochs: 74, Loss: 743293056.0, lr: 0.004
Epochs: 75, Loss: 737495616.0, lr: 0.004
Epochs: 76, Loss: 740695872.0, lr: 0.004
Epochs: 77, Loss: 748577792.0, lr: 0.004
Epochs: 78, Loss: 747556288.0, lr: 0.004
Epochs: 79, Loss: 732501312.0, lr: 0.004
Epochs: 80, Loss: 708543232.0, lr: 0.004
Epochs: 81, Loss: 684396800.0, lr: 0.004
Epochs: 82, Loss: 664595008.0, lr: 0.004
Epochs: 83, Loss: 648855168.0, lr: 0.004
Epochs: 84, Loss: 636224832.0, lr: 0.004
Epochs: 85, Loss: 627044288.0, lr: 0.004
Epochs: 86, Loss: 621954752.0, lr: 0.004
Epochs: 87, Loss: 618590656.0, lr: 0.004
Epochs: 88, Loss: 613543360.0, lr: 0.004
Epochs: 89, Loss: 604529600.0, lr: 0.004
Epochs: 90, Loss: 591742464.0, lr: 0.004
Epochs: 91, Loss: 577155136.0, lr: 0.004
Epochs: 92, Loss: 563756096.0, lr: 0.004
Epochs: 93, Loss: 552513152.0, lr: 0.004
Epochs: 94, Loss: 543738688.0, lr: 0.004
Epochs: 95, Loss: 538350016.0, lr: 0.004
Epochs: 96, Loss: 536083840.0, lr: 0.004
Epochs: 97, Loss: 534963392.0, lr: 0.004
Epochs: 98, Loss: 532387296.0, lr: 0.004
Epochs: 99, Loss: 526867872.0, lr: 0.004
Epochs: 100, Loss: 518969984.0, lr: 0.004
Epochs: 101, Loss: 510358432.0, lr: 0.004
Epochs: 102, Loss: 502289152.0, lr: 0.004
Epochs: 103, Loss: 495395584.0, lr: 0.004
Epochs: 104, Loss: 489963648.0, lr: 0.004
Epochs: 105, Loss: 485923584.0, lr: 0.004
Epochs: 106, Loss: 482972640.0, lr: 0.004
Epochs: 107, Loss: 480592288.0, lr: 0.004
Epochs: 108, Loss: 478163712.0, lr: 0.004
Epochs: 109, Loss: 475023712.0, lr: 0.004
Epochs: 110, Loss: 470652416.0, lr: 0.004
Epochs: 111, Loss: 465041184.0, lr: 0.004
Epochs: 112, Loss: 458719104.0, lr: 0.004
Epochs: 113, Loss: 452371488.0, lr: 0.004
Epochs: 114, Loss: 446397216.0, lr: 0.004
Epochs: 115, Loss: 440739040.0, lr: 0.004
Epochs: 116, Loss: 435016704.0, lr: 0.004
Epochs: 117, Loss: 428703872.0, lr: 0.004
Epochs: 118, Loss: 421258240.0, lr: 0.004
Epochs: 119, Loss: 412471200.0, lr: 0.004
Epochs: 120, Loss: 402567360.0, lr: 0.004
Epochs: 121, Loss: 391752512.0, lr: 0.004
Epochs: 122, Loss: 379885664.0, lr: 0.004
Epochs: 123, Loss: 366590656.0, lr: 0.004
Epochs: 124, Loss: 351540352.0, lr: 0.004
Epochs: 125, Loss: 335404224.0, lr: 0.004
Epochs: 126, Loss: 317488640.0, lr: 0.004
Epochs: 127, Loss: 295744064.0, lr: 0.004
Epochs: 128, Loss: 271093728.0, lr: 0.004
Epochs: 129, Loss: 245147328.0, lr: 0.004
Epochs: 130, Loss: 221063008.0, lr: 0.004
Epochs: 131, Loss: 201526960.0, lr: 0.004
Epochs: 132, Loss: 187090816.0, lr: 0.004
Epochs: 133, Loss: 177152448.0, lr: 0.004
Epochs: 134, Loss: 169162240.0, lr: 0.004
Epochs: 135, Loss: 160369696.0, lr: 0.004
Epochs: 136, Loss: 147619856.0, lr: 0.004
Epochs: 137, Loss: 131778872.0, lr: 0.004
Epochs: 138, Loss: 119674872.0, lr: 0.004
Epochs: 139, Loss: 109999112.0, lr: 0.004
Epochs: 140, Loss: 100602744.0, lr: 0.004
Epochs: 141, Loss: 91361592.0, lr: 0.004
Epochs: 142, Loss: 81602560.0, lr: 0.004
Epochs: 143, Loss: 73211152.0, lr: 0.004
Epochs: 144, Loss: 65998332.0, lr: 0.004
Epochs: 145, Loss: 58870828.0, lr: 0.004
Epochs: 146, Loss: 52677512.0, lr: 0.004
Epochs: 147, Loss: 47146072.0, lr: 0.004
Epochs: 148, Loss: 42276232.0, lr: 0.004
Epochs: 149, Loss: 38389112.0, lr: 0.004
Epochs: 150, Loss: 34629756.0, lr: 0.004
Epochs: 151, Loss: 31286078.0, lr: 0.004
Epochs: 152, Loss: 28964402.0, lr: 0.004
Epochs: 153, Loss: 27114834.0, lr: 0.004
Epochs: 154, Loss: 25756632.0, lr: 0.004
Epochs: 155, Loss: 24618904.0, lr: 0.004
Epochs: 156, Loss: 23175988.0, lr: 0.004
Epochs: 157, Loss: 21825608.0, lr: 0.004
Epochs: 158, Loss: 20661776.0, lr: 0.004
Epochs: 159, Loss: 19639346.0, lr: 0.004
Epochs: 160, Loss: 18790018.0, lr: 0.004
Epochs: 161, Loss: 17793956.0, lr: 0.004
Epochs: 162, Loss: 16877956.0, lr: 0.004
Epochs: 163, Loss: 16248537.0, lr: 0.004
Epochs: 164, Loss: 15744508.0, lr: 0.004
Epochs: 165, Loss: 15402699.0, lr: 0.004
Epochs: 166, Loss: 15062861.0, lr: 0.004
Epochs: 167, Loss: 14759372.0, lr: 0.004
Epochs: 168, Loss: 14557993.0, lr: 0.004
Epochs: 169, Loss: 14362308.0, lr: 0.004
Epochs: 170, Loss: 14236477.0, lr: 0.004
Epochs: 171, Loss: 14090112.0, lr: 0.004
Epochs: 172, Loss: 13969760.0, lr: 0.004
Epochs: 173, Loss: 13875928.0, lr: 0.004
Epochs: 174, Loss: 13779590.0, lr: 0.004
Epochs: 175, Loss: 13716056.0, lr: 0.004
Epochs: 176, Loss: 13629590.0, lr: 0.004
Epochs: 177, Loss: 13571713.0, lr: 0.004
Epochs: 178, Loss: 13508273.0, lr: 0.004
Epochs: 179, Loss: 13460214.0, lr: 0.004
Epochs: 180, Loss: 13412508.0, lr: 0.004
Epochs: 181, Loss: 13361804.0, lr: 0.004
Epochs: 182, Loss: 13324708.0, lr: 0.004
Epochs: 183, Loss: 13283595.0, lr: 0.004
Epochs: 184, Loss: 13255774.0, lr: 0.004
Epochs: 185, Loss: 13217094.0, lr: 0.004
Epochs: 186, Loss: 13189263.0, lr: 0.004
Epochs: 187, Loss: 13159364.0, lr: 0.004
Epochs: 188, Loss: 13137012.0, lr: 0.004
Epochs: 189, Loss: 13111597.0, lr: 0.004
Epochs: 190, Loss: 13086780.0, lr: 0.004
Epochs: 191, Loss: 13065770.0, lr: 0.004
Epochs: 192, Loss: 13045727.0, lr: 0.004
Epochs: 193, Loss: 13028559.0, lr: 0.004
Epochs: 194, Loss: 13007245.0, lr: 0.004
Epochs: 195, Loss: 12990560.0, lr: 0.004
Epochs: 196, Loss: 12973333.0, lr: 0.004
Epochs: 197, Loss: 12959670.0, lr: 0.004
Epochs: 198, Loss: 12942558.0, lr: 0.004
Epochs: 199, Loss: 12927550.0, lr: 0.004
Epochs: 200, Loss: 12913096.0, lr: 0.004
Epochs: 201, Loss: 12900690.0, lr: 0.004
Epochs: 202, Loss: 12887117.0, lr: 0.004
Epochs: 203, Loss: 12873144.0, lr: 0.004
Epochs: 204, Loss: 12860620.0, lr: 0.004
Epochs: 205, Loss: 12848907.0, lr: 0.004
Epochs: 206, Loss: 12837575.0, lr: 0.004
Epochs: 207, Loss: 12824790.0, lr: 0.004
Epochs: 208, Loss: 12813312.0, lr: 0.004
Epochs: 209, Loss: 12802273.0, lr: 0.004
Epochs: 210, Loss: 12792070.0, lr: 0.004
Epochs: 211, Loss: 12780577.0, lr: 0.004
Epochs: 212, Loss: 12769635.0, lr: 0.004
Epochs: 213, Loss: 12759211.0, lr: 0.004
Epochs: 214, Loss: 12749498.0, lr: 0.004
Epochs: 215, Loss: 12739108.0, lr: 0.004
Epochs: 216, Loss: 12728549.0, lr: 0.004
Epochs: 217, Loss: 12718569.0, lr: 0.004
Epochs: 218, Loss: 12709070.0, lr: 0.004
Epochs: 219, Loss: 12699423.0, lr: 0.004
Epochs: 220, Loss: 12689254.0, lr: 0.004
Epochs: 221, Loss: 12679514.0, lr: 0.004
Epochs: 222, Loss: 12670135.0, lr: 0.004
Epochs: 223, Loss: 12660876.0, lr: 0.004
Epochs: 224, Loss: 12651086.0, lr: 0.004
Epochs: 225, Loss: 12641456.0, lr: 0.004
Epochs: 226, Loss: 12632134.0, lr: 0.004
Epochs: 227, Loss: 12623011.0, lr: 0.004
Epochs: 228, Loss: 12613520.0, lr: 0.004
Epochs: 229, Loss: 12603943.0, lr: 0.004
Epochs: 230, Loss: 12594613.0, lr: 0.004
Epochs: 231, Loss: 12585478.0, lr: 0.004
Epochs: 232, Loss: 12576160.0, lr: 0.004
Epochs: 233, Loss: 12566613.0, lr: 0.004
Epochs: 234, Loss: 12557222.0, lr: 0.004
Epochs: 235, Loss: 12547997.0, lr: 0.004
Epochs: 236, Loss: 12538717.0, lr: 0.004
Epochs: 237, Loss: 12529180.0, lr: 0.004
Epochs: 238, Loss: 12519685.0, lr: 0.004
Epochs: 239, Loss: 12510324.0, lr: 0.004
Epochs: 240, Loss: 12500972.0, lr: 0.004
Epochs: 241, Loss: 12491412.0, lr: 0.004
Epochs: 242, Loss: 12481787.0, lr: 0.004
Epochs: 243, Loss: 12472255.0, lr: 0.004
Epochs: 244, Loss: 12462764.0, lr: 0.004
Epochs: 245, Loss: 12453119.0, lr: 0.004
Epochs: 246, Loss: 12443355.0, lr: 0.004
Epochs: 247, Loss: 12433631.0, lr: 0.004
Epochs: 248, Loss: 12423946.0, lr: 0.004
Epochs: 249, Loss: 12414160.0, lr: 0.004
Epochs: 250, Loss: 12404233.0, lr: 0.001
########## Saving Trace ##########
Traceback (most recent call last):
  File "tv_value_synthesis_trajopt_cartpole.py", line 179, in <module>
    loss = loss_function(traj, dtraj_dt, alpha)
KeyboardInterrupt
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "tv_value_synthesis_trajopt_cartpole.py", line 218, in <module>
    model_scripted = torch.jit.script(dyn_system.value_func.to('cpu'))  # Export to TorchScript
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/jit/_script.py", line 1287, in script
    obj, torch.jit._recursive.infer_methods_to_compile
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/jit/_recursive.py", line 476, in create_script_module
    return create_script_module_impl(nn_module, concrete_type, stubs_fn)
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/jit/_recursive.py", line 542, in create_script_module_impl
    create_methods_and_properties_from_stubs(concrete_type, method_stubs, property_stubs)
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/jit/_recursive.py", line 393, in create_methods_and_properties_from_stubs
    concrete_type._create_methods_and_properties(property_defs, property_rcbs, method_defs, method_rcbs, method_defaults)
RuntimeError:
attribute lookup is not defined on python value of type 'SimulationParams':
  File "tv_value_synthesis_trajopt_cartpole.py", line 64
    def forward(self, t, x):
        time = torch.ones((sim_params.nsim, 1, 1)).to(device) * t
                           ~~~~~~~~~~~~~~~ <--- HERE
        aug_x = torch.cat((x, time), dim=2)
        return self.nn(aug_x)