
Creating window glfw
Epochs: 0, Loss: 2194856704.0, lr: 0.004
Epochs: 1, Loss: 2142582400.0, lr: 0.004
Epochs: 2, Loss: 2090900224.0, lr: 0.004
Epochs: 3, Loss: 2038301568.0, lr: 0.004
Epochs: 4, Loss: 1984717568.0, lr: 0.004
Epochs: 5, Loss: 1930468352.0, lr: 0.004
Epochs: 6, Loss: 1875889024.0, lr: 0.004
Epochs: 7, Loss: 1821136640.0, lr: 0.004
Epochs: 8, Loss: 1766144640.0, lr: 0.004
Epochs: 9, Loss: 1710738048.0, lr: 0.004
Epochs: 10, Loss: 1654978048.0, lr: 0.004
Epochs: 11, Loss: 1599570048.0, lr: 0.004
Epochs: 12, Loss: 1545441664.0, lr: 0.004
Epochs: 13, Loss: 1493160320.0, lr: 0.004
Epochs: 14, Loss: 1443586816.0, lr: 0.004
Epochs: 15, Loss: 1398138752.0, lr: 0.004
Epochs: 16, Loss: 1357315328.0, lr: 0.004
Epochs: 17, Loss: 1319977728.0, lr: 0.004
Epochs: 18, Loss: 1284217472.0, lr: 0.004
Epochs: 19, Loss: 1250009472.0, lr: 0.004
Epochs: 20, Loss: 1220238336.0, lr: 0.004
Epochs: 21, Loss: 1198680064.0, lr: 0.004
Epochs: 22, Loss: 1187097216.0, lr: 0.004
Epochs: 23, Loss: 1183479936.0, lr: 0.004
Epochs: 24, Loss: 1181097472.0, lr: 0.004
Epochs: 25, Loss: 1174582528.0, lr: 0.004
Epochs: 26, Loss: 1159391616.0, lr: 0.004
Epochs: 27, Loss: 1132893440.0, lr: 0.004
Epochs: 28, Loss: 1097049344.0, lr: 0.004
Epochs: 29, Loss: 1053937216.0, lr: 0.004
Epochs: 30, Loss: 1009430976.0, lr: 0.004
Epochs: 31, Loss: 969281856.0, lr: 0.004
Epochs: 32, Loss: 937664896.0, lr: 0.004
Epochs: 33, Loss: 905720448.0, lr: 0.004
Epochs: 34, Loss: 879828992.0, lr: 0.004
Epochs: 35, Loss: 858216000.0, lr: 0.004
Epochs: 36, Loss: 836438208.0, lr: 0.004
Epochs: 37, Loss: 816395904.0, lr: 0.004
Epochs: 38, Loss: 804644800.0, lr: 0.004
Epochs: 39, Loss: 791491008.0, lr: 0.004
Epochs: 40, Loss: 778170112.0, lr: 0.004
Epochs: 41, Loss: 765020544.0, lr: 0.004
Epochs: 42, Loss: 751864640.0, lr: 0.004
Epochs: 43, Loss: 738425344.0, lr: 0.004
Epochs: 44, Loss: 724478592.0, lr: 0.004
Epochs: 45, Loss: 710255232.0, lr: 0.004
Epochs: 46, Loss: 697869632.0, lr: 0.004
Epochs: 47, Loss: 685177920.0, lr: 0.004
Epochs: 48, Loss: 670929728.0, lr: 0.004
Epochs: 49, Loss: 655411136.0, lr: 0.004
Epochs: 50, Loss: 638918144.0, lr: 0.004
Epochs: 51, Loss: 620910720.0, lr: 0.004
Epochs: 52, Loss: 601127168.0, lr: 0.004
Epochs: 53, Loss: 583246976.0, lr: 0.004
Epochs: 54, Loss: 566782208.0, lr: 0.004
Epochs: 55, Loss: 549098880.0, lr: 0.004
Epochs: 56, Loss: 528345888.0, lr: 0.004
Epochs: 57, Loss: 511392608.0, lr: 0.004
Epochs: 58, Loss: 498435008.0, lr: 0.004
Epochs: 59, Loss: 485897184.0, lr: 0.004
Epochs: 60, Loss: 473886624.0, lr: 0.004
Epochs: 61, Loss: 460117568.0, lr: 0.004
Epochs: 62, Loss: 446431136.0, lr: 0.004
Epochs: 63, Loss: 435281728.0, lr: 0.004
Epochs: 64, Loss: 427457824.0, lr: 0.004
Epochs: 65, Loss: 419870304.0, lr: 0.004
Epochs: 66, Loss: 411425568.0, lr: 0.004
Epochs: 67, Loss: 404572352.0, lr: 0.004
Epochs: 68, Loss: 396019008.0, lr: 0.004
Epochs: 69, Loss: 388325536.0, lr: 0.004
Epochs: 70, Loss: 377644096.0, lr: 0.004
Epochs: 71, Loss: 365261792.0, lr: 0.004
Epochs: 72, Loss: 355102976.0, lr: 0.004
Epochs: 73, Loss: 347221856.0, lr: 0.004
Epochs: 74, Loss: 343083360.0, lr: 0.004
Epochs: 75, Loss: 338431200.0, lr: 0.004
Epochs: 76, Loss: 327059648.0, lr: 0.004
Epochs: 77, Loss: 318965184.0, lr: 0.004
Epochs: 78, Loss: 311650240.0, lr: 0.004
Epochs: 79, Loss: 305877248.0, lr: 0.004
Epochs: 80, Loss: 300542272.0, lr: 0.004
Epochs: 81, Loss: 296347840.0, lr: 0.004
Epochs: 82, Loss: 288559424.0, lr: 0.004
Epochs: 83, Loss: 283749504.0, lr: 0.004
Epochs: 84, Loss: 278891456.0, lr: 0.004
Epochs: 85, Loss: 271788352.0, lr: 0.004
Epochs: 86, Loss: 265510528.0, lr: 0.004
Epochs: 87, Loss: 260490528.0, lr: 0.004
Epochs: 88, Loss: 255027856.0, lr: 0.004
Epochs: 89, Loss: 246526240.0, lr: 0.004
Epochs: 90, Loss: 237148208.0, lr: 0.004
Epochs: 91, Loss: 226370064.0, lr: 0.004
Epochs: 92, Loss: 216765120.0, lr: 0.004
Epochs: 93, Loss: 208033376.0, lr: 0.004
Epochs: 94, Loss: 198321280.0, lr: 0.004
Epochs: 95, Loss: 192284768.0, lr: 0.004
Epochs: 96, Loss: 188348608.0, lr: 0.004
Epochs: 97, Loss: 184678400.0, lr: 0.004
Epochs: 98, Loss: 180899040.0, lr: 0.004
Epochs: 99, Loss: 176688096.0, lr: 0.004
Epochs: 100, Loss: 171469616.0, lr: 0.004
Epochs: 101, Loss: 165527296.0, lr: 0.004
Epochs: 102, Loss: 159316720.0, lr: 0.004
Epochs: 103, Loss: 152914640.0, lr: 0.004
Epochs: 104, Loss: 146546208.0, lr: 0.004
Epochs: 105, Loss: 140018192.0, lr: 0.004
Epochs: 106, Loss: 132726536.0, lr: 0.004
Epochs: 107, Loss: 124887208.0, lr: 0.004
Epochs: 108, Loss: 117011288.0, lr: 0.004
Epochs: 109, Loss: 109356600.0, lr: 0.004
Epochs: 110, Loss: 102254528.0, lr: 0.004
Epochs: 111, Loss: 95591648.0, lr: 0.004
Epochs: 112, Loss: 89360400.0, lr: 0.004
Epochs: 113, Loss: 83800792.0, lr: 0.004
Epochs: 114, Loss: 78816560.0, lr: 0.004
Epochs: 115, Loss: 74425944.0, lr: 0.004
Epochs: 116, Loss: 70396744.0, lr: 0.004
Epochs: 117, Loss: 66723728.0, lr: 0.004
Epochs: 118, Loss: 63500780.0, lr: 0.004
Epochs: 119, Loss: 60619208.0, lr: 0.004
Epochs: 120, Loss: 58050664.0, lr: 0.004
Epochs: 121, Loss: 55644196.0, lr: 0.004
Epochs: 122, Loss: 53514956.0, lr: 0.004
Epochs: 123, Loss: 51610460.0, lr: 0.004
Epochs: 124, Loss: 49943408.0, lr: 0.004
Epochs: 125, Loss: 48371004.0, lr: 0.004
Epochs: 126, Loss: 46989608.0, lr: 0.004
Epochs: 127, Loss: 45794708.0, lr: 0.004
Epochs: 128, Loss: 44748664.0, lr: 0.004
Epochs: 129, Loss: 43729308.0, lr: 0.004
Epochs: 130, Loss: 42858088.0, lr: 0.004
Epochs: 131, Loss: 42130628.0, lr: 0.004
Epochs: 132, Loss: 41396872.0, lr: 0.004
Epochs: 133, Loss: 40706936.0, lr: 0.004
Epochs: 134, Loss: 40134840.0, lr: 0.004
Epochs: 135, Loss: 39575532.0, lr: 0.004
Epochs: 136, Loss: 38986256.0, lr: 0.004
Epochs: 137, Loss: 38495756.0, lr: 0.004
Epochs: 138, Loss: 38026976.0, lr: 0.004
Epochs: 139, Loss: 37516188.0, lr: 0.004
Epochs: 140, Loss: 37095732.0, lr: 0.004
Epochs: 141, Loss: 36689848.0, lr: 0.004
Epochs: 142, Loss: 36265280.0, lr: 0.004
Epochs: 143, Loss: 35925140.0, lr: 0.004
Epochs: 144, Loss: 35574760.0, lr: 0.004
Epochs: 145, Loss: 35243916.0, lr: 0.004
Epochs: 146, Loss: 34976036.0, lr: 0.004
Epochs: 147, Loss: 34676876.0, lr: 0.004
Epochs: 148, Loss: 34425856.0, lr: 0.004
Epochs: 149, Loss: 34190836.0, lr: 0.004
Epochs: 150, Loss: 33948280.0, lr: 0.004
Epochs: 151, Loss: 33747424.0, lr: 0.004
Epochs: 152, Loss: 33522498.0, lr: 0.004
Epochs: 153, Loss: 33328674.0, lr: 0.004
Epochs: 154, Loss: 33133628.0, lr: 0.004
Epochs: 155, Loss: 32944480.0, lr: 0.004
Epochs: 156, Loss: 32774918.0, lr: 0.004
Epochs: 157, Loss: 32593636.0, lr: 0.004
Epochs: 158, Loss: 32440182.0, lr: 0.004
Epochs: 159, Loss: 32271392.0, lr: 0.004
Epochs: 160, Loss: 32129864.0, lr: 0.004
Epochs: 161, Loss: 31976498.0, lr: 0.004
Epochs: 162, Loss: 31846154.0, lr: 0.004
Epochs: 163, Loss: 31707964.0, lr: 0.004
Epochs: 164, Loss: 31588856.0, lr: 0.004
Epochs: 165, Loss: 31463762.0, lr: 0.004
Epochs: 166, Loss: 31356122.0, lr: 0.004
Epochs: 167, Loss: 31241488.0, lr: 0.004
Epochs: 168, Loss: 31146362.0, lr: 0.004
Epochs: 169, Loss: 31040080.0, lr: 0.004
Epochs: 170, Loss: 30962170.0, lr: 0.004
Epochs: 171, Loss: 30866868.0, lr: 0.004
Epochs: 172, Loss: 30827986.0, lr: 0.004
Epochs: 173, Loss: 30776974.0, lr: 0.004
Epochs: 174, Loss: 30879426.0, lr: 0.004
Epochs: 175, Loss: 31034380.0, lr: 0.004
Epochs: 176, Loss: 31476726.0, lr: 0.004
Epochs: 177, Loss: 31599152.0, lr: 0.004
Epochs: 178, Loss: 31216796.0, lr: 0.004
Epochs: 179, Loss: 30382032.0, lr: 0.004
Epochs: 180, Loss: 30268708.0, lr: 0.004
Epochs: 181, Loss: 30737548.0, lr: 0.004
Epochs: 182, Loss: 30712338.0, lr: 0.004
Epochs: 183, Loss: 30191536.0, lr: 0.004
Epochs: 184, Loss: 30010916.0, lr: 0.004
Epochs: 185, Loss: 30301748.0, lr: 0.004
Epochs: 186, Loss: 30283502.0, lr: 0.004
Epochs: 187, Loss: 29894546.0, lr: 0.004
Epochs: 188, Loss: 29829490.0, lr: 0.004
Epochs: 189, Loss: 30017848.0, lr: 0.004
Epochs: 190, Loss: 29925730.0, lr: 0.004
Epochs: 191, Loss: 29650572.0, lr: 0.004
Epochs: 192, Loss: 29658574.0, lr: 0.004
Epochs: 193, Loss: 29778434.0, lr: 0.004
Epochs: 194, Loss: 29623382.0, lr: 0.004
Epochs: 195, Loss: 29463440.0, lr: 0.004
Epochs: 196, Loss: 29503502.0, lr: 0.004
Epochs: 197, Loss: 29519000.0, lr: 0.004
Epochs: 198, Loss: 29417086.0, lr: 0.004
Epochs: 199, Loss: 29295370.0, lr: 0.004
Epochs: 200, Loss: 29306616.0, lr: 0.004
Epochs: 201, Loss: 29335568.0, lr: 0.004
Epochs: 202, Loss: 29210602.0, lr: 0.004
Epochs: 203, Loss: 29134302.0, lr: 0.004
Epochs: 204, Loss: 29146212.0, lr: 0.004
Epochs: 205, Loss: 29116842.0, lr: 0.004
Epochs: 206, Loss: 29062310.0, lr: 0.004
Epochs: 207, Loss: 28975506.0, lr: 0.004
Epochs: 208, Loss: 28950158.0, lr: 0.004
Epochs: 209, Loss: 28958654.0, lr: 0.004
Epochs: 210, Loss: 28883166.0, lr: 0.004
Epochs: 211, Loss: 28825720.0, lr: 0.004
Epochs: 212, Loss: 28786038.0, lr: 0.004
Epochs: 213, Loss: 28756094.0, lr: 0.004
Epochs: 214, Loss: 28739596.0, lr: 0.004
Epochs: 215, Loss: 28664564.0, lr: 0.004
Epochs: 216, Loss: 28616998.0, lr: 0.004
Epochs: 217, Loss: 28586782.0, lr: 0.004
Epochs: 218, Loss: 28547208.0, lr: 0.004
Epochs: 219, Loss: 28521632.0, lr: 0.004
Epochs: 220, Loss: 28455576.0, lr: 0.004
Epochs: 221, Loss: 28411144.0, lr: 0.004
########## Saving Trace ##########
Traceback (most recent call last):
  File "tv_value_synthesis_trajopt_cartpole.py", line 180, in <module>
    loss.backward()
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/_tensor.py", line 488, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "tv_value_synthesis_trajopt_cartpole.py", line 218, in <module>
    model_scripted = torch.jit.script(dyn_system.value_func.to('cpu'))  # Export to TorchScript
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/jit/_script.py", line 1287, in script
    obj, torch.jit._recursive.infer_methods_to_compile
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/jit/_recursive.py", line 476, in create_script_module
    return create_script_module_impl(nn_module, concrete_type, stubs_fn)
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/jit/_recursive.py", line 542, in create_script_module_impl
    create_methods_and_properties_from_stubs(concrete_type, method_stubs, property_stubs)
  File "/home/daniel/.local/share/virtualenvs/Mujoco_Python_Sandbox-gNKKWzd6/lib/python3.7/site-packages/torch/jit/_recursive.py", line 393, in create_methods_and_properties_from_stubs
    concrete_type._create_methods_and_properties(property_defs, property_rcbs, method_defs, method_rcbs, method_defaults)
RuntimeError:
attribute lookup is not defined on python value of type 'SimulationParams':
  File "tv_value_synthesis_trajopt_cartpole.py", line 64
    def forward(self, t, x):
        time = torch.ones((sim_params.nsim, 1, 1)).to(device) * t
                           ~~~~~~~~~~~~~~~ <--- HERE
        aug_x = torch.cat((x, time), dim=2)
        return self.nn(aug_x)